{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyMoney preprocessing (Purchase Propensity Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, RepeatedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import category_encoders as ce\n",
    "\n",
    "import folium\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "set_config(transform_output = \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with these versions of libraries\n",
      "\n",
      "Numpy version 1.26.4\n",
      "Pandas version 2.1.4\n",
      "Statsmodels version 0.14.0\n",
      "Sklearn version 1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Working with these versions of libraries\\n\")\n",
    "print(f\"Numpy version {np.__version__}\")\n",
    "print(f\"Pandas version {pd.__version__}\")\n",
    "print(f\"Statsmodels version {sm.__version__}\")\n",
    "print(f\"Sklearn version {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\Usuario\\Desktop\\Proyects\\Easy Money\\data_compressed'\n",
    "file_name =  r\"\\customer_commercial_activity.csv\"\n",
    "file_name1 = r\"\\customer_products.csv\"\n",
    "file_name2 = r\"\\customer_sociodemographics.csv\"\n",
    "file_name3 = r\"\\product_description.csv\"\n",
    "file_name4 = r\"\\sales.csv\"\n",
    "cca = pd.read_csv(PATH + file_name, sep = \",\", index_col=0)\n",
    "cp = pd.read_csv(PATH + file_name1, sep = \",\", index_col=0)\n",
    "cs = pd.read_csv(PATH + file_name2, sep = \",\", index_col=0)\n",
    "prd = pd.read_csv(PATH + file_name3, sep = \",\", index_col=0)\n",
    "sales = pd.read_csv(PATH + file_name4, sep = \",\", index_col=0)\n",
    "\n",
    "dfs = [cca, cp, cs, sales]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling data\n",
    "\n",
    "def sampling_xdf(dfs, p_sample):\n",
    "    sampled_dfs = []\n",
    "    for df in dfs:\n",
    "        n_rows = int(len(df)*p_sample)\n",
    "        sampled_df = df.sample(n = n_rows, random_state = 42)\n",
    "        sampled_dfs.append(sampled_df)\n",
    "    return sampled_dfs\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "def setOthers(dataframe, column, num_values, fillvalue):\n",
    "    top_categories = dataframe[column].value_counts().head(num_values)\n",
    "    top_categories_list = top_categories.index.to_list()\n",
    "    top_categories_list.append(fillvalue)\n",
    "    dataframe[column] = pd.Categorical(dataframe[column], categories=top_categories_list)\n",
    "    return dataframe[column].fillna(fillvalue)\n",
    "\n",
    "def seniority(df, date_column, threshold_date):\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    df['customer_seniority'] = 'Old'\n",
    "    df.loc[df.groupby('pk_cid')[date_column].transform('min') >= threshold_date, 'customer_seniority'] = 'New'\n",
    "\n",
    "    return df\n",
    "\n",
    "## Calculation functions\n",
    "\n",
    "def calc_moda(series):\n",
    "    return series.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca, cp, cs, sales = sampling_xdf(dfs, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Sales_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_data(sales, prd):\n",
    "    prd = prd.rename(columns={'pk_product_ID': 'product_ID'})\n",
    "    sales = sales.rename(columns={'cid' : 'pk_cid'})\n",
    "    sales['month_sale_int'] = pd.to_datetime(sales['month_sale']).dt.strftime('%Y%m%d').astype(int)\n",
    "    sales_prd = sales.merge(prd, on= 'product_ID', how= 'inner')\n",
    "\n",
    "    sales_prd_merge = sales_prd.groupby('pk_cid').agg(\n",
    "    T_sales = ('pk_sale', 'count'),\n",
    "    n_product = ('product_desc', 'count'),\n",
    "    T_net_margin = ('net_margin', 'sum'),\n",
    "    Mean_net_margin = ('net_margin', 'mean'),\n",
    "    first_sale = ('month_sale_int', 'min'),\n",
    "    last_sale = ('month_sale_int', 'max'),\n",
    "    product_moda = ('product_ID', calc_moda))\n",
    "    \n",
    "    return sales_prd_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_prd_merge = get_sales_data(sales, prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22629"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['cid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8568"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_prd_merge.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Customers information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_top_features(df):\n",
    "    customers_merge = df.groupby('pk_cid').agg(\n",
    "        entry_channel_nunique = ('entry_channel_so', pd.Series.nunique),\n",
    "        entry_channel_most_freq = ('entry_channel_so', calc_moda),\n",
    "        act_cust_most_freq = ('active_customer', 'mean'),\n",
    "        act_cust_std = ('active_customer', 'std'),\n",
    "        afiliation_time = ('afiliation_time', 'max'),\n",
    "        salary = ('salary_imp', 'mean'),\n",
    "        age = ('age', 'max'),\n",
    "        region_code = ('region_code_so', calc_moda),\n",
    "        entry_date = ('entry_date', 'min'),\n",
    "        segment = ('segment_so', calc_moda),\n",
    "        customer_seniority = ('customer_seniority', calc_moda)\n",
    "        )\n",
    "    customers_merge['act_cust_std'] = customers_merge['act_cust_std'].fillna(-1)\n",
    "    return customers_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customers_data(cca, cs):\n",
    "        cust = cca.merge(cs, on = ['pk_cid', 'pk_partition'], how = 'inner')\n",
    "\n",
    "        cust = cust[cust['deceased']== 'N'].drop('deceased', axis =  1)\n",
    "        cust_es = pd.DataFrame(cust[cust['country_id'] == 'ES'].drop('country_id', axis = 1))\n",
    "\n",
    "        cust_es['active_customer'] = cust_es['active_customer'].astype(int)\n",
    "        cust_es['pk_partition'] = pd.to_datetime(cust_es['pk_partition'])\n",
    "        cust_es['entry_date'] = pd.to_datetime(cust_es['entry_date'])\n",
    "        cust_es['afiliation_time'] = cust_es['pk_partition'] - cust_es['entry_date']\n",
    "\n",
    "        cust_es['gender_mf'] = SimpleImputer(strategy =  'most_frequent').fit_transform(\n",
    "                cust_es[['gender']])\n",
    "        sal_mn_regage = cust_es.groupby(['age', 'region_code'])['salary'].transform('mean')\n",
    "        cust_es['salary_imp'] = cust_es['salary'].fillna(sal_mn_regage).round(2)\n",
    "        cust_es['salary_imp'] = SimpleImputer(strategy = 'mean').fit_transform(cust_es[['salary_imp']])\n",
    "\n",
    "        cust_es['segment_so'] = setOthers(cust_es, 'segment', 2, '03 - Other')\n",
    "        cust_es['entry_channel_so'] = setOthers(cust_es, 'entry_channel', 10, 'ZZZ')\n",
    "        cust_es['region_code_so'] = setOthers(cust_es, 'region_code', 45, 99.0)\n",
    "        threshold_date = pd.to_datetime('2018-01-01')\n",
    "        cust_es = seniority(cust_es, 'entry_date', threshold_date)\n",
    "        return cust_top_features(cust_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_es_merge = get_customers_data(cca, cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19867"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_es_merge.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Customers products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6059396     2018-09\n",
       "10140464    2019-02\n",
       "8908827     2018-12\n",
       "7690470     2018-11\n",
       "13548914    2019-05\n",
       "             ...   \n",
       "9741584     2019-01\n",
       "10962229    2019-03\n",
       "10081762    2019-02\n",
       "10601550    2019-02\n",
       "10001199    2019-02\n",
       "Name: pk_partition, Length: 596292, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp['pk_partition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getproductdata(dataset):\n",
    "  dataset.fillna(0, inplace = True)\n",
    "  #dataset['pk_partition'] = pd.to_datetime(dataset['pk_partition']).dt.strftime('%Y%m%d').astype(int)\n",
    "  products = dataset.drop(['pk_cid', 'pk_partition'], axis=1).columns\n",
    "  dataset['Products_holding_sum'] = dataset[products].sum(axis = 1)\n",
    "  dataset['Products_contracted'] = dataset.select_dtypes(include = np.number).sum(axis = 1)\n",
    "  cust_products_merge = dataset.groupby('pk_cid').agg(\n",
    "    mean_products_contracted = ('Products_contracted','mean'),\n",
    "    std_products_contracted = ('Products_contracted','std'),\n",
    "    max_products_contracted = ('Products_contracted','max'),\n",
    "    min_products_contracted = ('Products_contracted','min'))\n",
    "  cust_products_merge['std_products_contracted'].fillna(-1, inplace = True)\n",
    "\n",
    "  return cust_products_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_products_contracted</th>\n",
       "      <th>std_products_contracted</th>\n",
       "      <th>max_products_contracted</th>\n",
       "      <th>min_products_contracted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pk_cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>48616.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>48616.0</td>\n",
       "      <td>48616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16502</th>\n",
       "      <td>49516.5</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>49520.0</td>\n",
       "      <td>49513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17457</th>\n",
       "      <td>52388.5</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>52392.0</td>\n",
       "      <td>52385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17590</th>\n",
       "      <td>52770.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52770.0</td>\n",
       "      <td>52770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17799</th>\n",
       "      <td>53404.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>53404.0</td>\n",
       "      <td>53404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_products_contracted  std_products_contracted  \\\n",
       "pk_cid                                                      \n",
       "16203                    48616.0                -1.000000   \n",
       "16502                    49516.5                 4.949747   \n",
       "17457                    52388.5                 4.949747   \n",
       "17590                    52770.0                 0.000000   \n",
       "17799                    53404.0                -1.000000   \n",
       "\n",
       "        max_products_contracted  min_products_contracted  \n",
       "pk_cid                                                    \n",
       "16203                   48616.0                  48616.0  \n",
       "16502                   49520.0                  49513.0  \n",
       "17457                   52392.0                  52385.0  \n",
       "17590                   52770.0                  52770.0  \n",
       "17799                   53404.0                  53404.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_products_merge =getproductdata(cp)\n",
    "cust_products_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergedataset_(cust_es_merge, cust_products_merge, sales_prd_merge):\n",
    "  full_df = pd.merge(cust_es_merge, cust_products_merge, how = 'inner', left_index = True, right_index = True)\n",
    "  full_df = pd.merge(full_df, sales_prd_merge, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "  full_df['afiliation_days'] = full_df['afiliation_time'].dt.days\n",
    "  full_df.drop(columns = 'afiliation_time', axis = 1, inplace = True)\n",
    "  full_df['act_cust_most_freq'] = full_df['act_cust_most_freq'].astype(float)\n",
    "  full_df.dropna(inplace = True)\n",
    "  full_df['entry_date_int'] = pd.to_datetime(full_df['entry_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "  full_df.drop('entry_date', axis= 1, inplace = True)\n",
    "\n",
    "  return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergedataset(cust_es_merge, cust_products_merge, sales_prd_merge):\n",
    "  full_df = pd.merge(cust_es_merge, cust_products_merge, how = 'inner', left_index = True, right_index = True)\n",
    "  full_df = pd.merge(full_df, sales_prd_merge, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "  full_df['afiliation_days'] = full_df['afiliation_time'].dt.days\n",
    "  full_df.drop(columns = 'afiliation_time', axis = 1, inplace = True)\n",
    "  full_df['act_cust_most_freq'] = full_df['act_cust_most_freq'].astype(float)\n",
    "  full_df.fillna(0, inplace = True)\n",
    "  full_df['entry_date_int'] = pd.to_datetime(full_df['entry_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "  full_df.drop('entry_date', axis= 1, inplace = True)\n",
    "\n",
    "  return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_ = mergedataset_(cust_es_merge, cust_products_merge, sales_prd_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = mergedataset(cust_es_merge, cust_products_merge, sales_prd_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14861, 22)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324676, 22)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 324676 entries, 16203 to 1553680\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   entry_channel_nunique     324676 non-null  int64  \n",
      " 1   entry_channel_most_freq   324676 non-null  object \n",
      " 2   act_cust_most_freq        324676 non-null  float64\n",
      " 3   act_cust_std              324676 non-null  float64\n",
      " 4   salary                    324676 non-null  float64\n",
      " 5   age                       324676 non-null  int64  \n",
      " 6   region_code               324676 non-null  float64\n",
      " 7   segment                   324676 non-null  object \n",
      " 8   customer_seniority        324676 non-null  object \n",
      " 9   mean_products_contracted  324676 non-null  float64\n",
      " 10  std_products_contracted   324676 non-null  float64\n",
      " 11  max_products_contracted   324676 non-null  float64\n",
      " 12  min_products_contracted   324676 non-null  float64\n",
      " 13  T_sales                   324676 non-null  float64\n",
      " 14  n_product                 324676 non-null  float64\n",
      " 15  T_net_margin              324676 non-null  float64\n",
      " 16  Mean_net_margin           324676 non-null  float64\n",
      " 17  first_sale                324676 non-null  float64\n",
      " 18  last_sale                 324676 non-null  float64\n",
      " 19  product_moda              324676 non-null  float64\n",
      " 20  afiliation_days           324676 non-null  int64  \n",
      " 21  entry_date_int            324676 non-null  int32  \n",
      "dtypes: float64(15), int32(1), int64(3), object(3)\n",
      "memory usage: 63.8+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_transform(df):\n",
    "  #numerical_columns_v2 = df.select_dtypes(exclude = object).drop(['region_code', 'product_moda'], axis=1).columns.to_list()\n",
    "  numerical_columns_v2 = df.select_dtypes(exclude = object).drop('region_code', axis=1).columns.to_list()\n",
    "  transform_pipe = ColumnTransformer(transformers = [\n",
    "    (\"scaler\", MinMaxScaler(), numerical_columns_v2),\n",
    "    (\"encoder\", OneHotEncoder(sparse_output = False), ['entry_channel_most_freq', 'segment', 'product_moda']),\n",
    "    #(\"encoder\", OneHotEncoder(sparse_output = False), ['entry_channel_most_freq', 'segment', 'product_moda']),\n",
    "    ('ordinal', OrdinalEncoder(), ['region_code', 'customer_seniority'])\n",
    "    ])\n",
    "  full_df_trans = transform_pipe.fit_transform(df)\n",
    "  return full_df_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_trans = prep_transform(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_trans_ = prep_transform(full_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 324676 entries, 16203 to 1553680\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   scaler__entry_channel_nunique         324676 non-null  float64\n",
      " 1   scaler__act_cust_most_freq            324676 non-null  float64\n",
      " 2   scaler__act_cust_std                  324676 non-null  float64\n",
      " 3   scaler__salary                        324676 non-null  float64\n",
      " 4   scaler__age                           324676 non-null  float64\n",
      " 5   scaler__mean_products_contracted      324676 non-null  float64\n",
      " 6   scaler__std_products_contracted       324676 non-null  float64\n",
      " 7   scaler__max_products_contracted       324676 non-null  float64\n",
      " 8   scaler__min_products_contracted       324676 non-null  float64\n",
      " 9   scaler__T_sales                       324676 non-null  float64\n",
      " 10  scaler__n_product                     324676 non-null  float64\n",
      " 11  scaler__T_net_margin                  324676 non-null  float64\n",
      " 12  scaler__Mean_net_margin               324676 non-null  float64\n",
      " 13  scaler__first_sale                    324676 non-null  float64\n",
      " 14  scaler__last_sale                     324676 non-null  float64\n",
      " 15  scaler__product_moda                  324676 non-null  float64\n",
      " 16  scaler__afiliation_days               324676 non-null  float64\n",
      " 17  scaler__entry_date_int                324676 non-null  float64\n",
      " 18  encoder__entry_channel_most_freq_KAT  324676 non-null  float64\n",
      " 19  encoder__entry_channel_most_freq_KFA  324676 non-null  float64\n",
      " 20  encoder__entry_channel_most_freq_KFC  324676 non-null  float64\n",
      " 21  encoder__entry_channel_most_freq_KHD  324676 non-null  float64\n",
      " 22  encoder__entry_channel_most_freq_KHE  324676 non-null  float64\n",
      " 23  encoder__entry_channel_most_freq_KHK  324676 non-null  float64\n",
      " 24  encoder__entry_channel_most_freq_KHM  324676 non-null  float64\n",
      " 25  encoder__entry_channel_most_freq_KHN  324676 non-null  float64\n",
      " 26  encoder__entry_channel_most_freq_KHQ  324676 non-null  float64\n",
      " 27  encoder__entry_channel_most_freq_RED  324676 non-null  float64\n",
      " 28  encoder__entry_channel_most_freq_ZZZ  324676 non-null  float64\n",
      " 29  encoder__segment_02 - PARTICULARES    324676 non-null  float64\n",
      " 30  encoder__segment_03 - Other           324676 non-null  float64\n",
      " 31  encoder__segment_03 - UNIVERSITARIO   324676 non-null  float64\n",
      " 32  encoder__product_moda_0.0             324676 non-null  float64\n",
      " 33  encoder__product_moda_1119.0          324676 non-null  float64\n",
      " 34  encoder__product_moda_1364.0          324676 non-null  float64\n",
      " 35  encoder__product_moda_2234.0          324676 non-null  float64\n",
      " 36  encoder__product_moda_2235.0          324676 non-null  float64\n",
      " 37  encoder__product_moda_2312.0          324676 non-null  float64\n",
      " 38  encoder__product_moda_2335.0          324676 non-null  float64\n",
      " 39  encoder__product_moda_2336.0          324676 non-null  float64\n",
      " 40  encoder__product_moda_2673.0          324676 non-null  float64\n",
      " 41  encoder__product_moda_3819.0          324676 non-null  float64\n",
      " 42  encoder__product_moda_4657.0          324676 non-null  float64\n",
      " 43  encoder__product_moda_8871.0          324676 non-null  float64\n",
      " 44  encoder__product_moda_9001.0          324676 non-null  float64\n",
      " 45  ordinal__region_code                  324676 non-null  float64\n",
      " 46  ordinal__customer_seniority           324676 non-null  float64\n",
      "dtypes: float64(47)\n",
      "memory usage: 127.0 MB\n"
     ]
    }
   ],
   "source": [
    "full_df_trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "em_propensity = full_df_trans.drop_duplicates()\n",
    "prd_prop_to_merge = cp.drop('pk_partition', axis=1).drop_duplicates().set_index('pk_cid')\n",
    "em_propensity_pp = pd.merge(em_propensity, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'pension_plan']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_emc = pd.merge(em_propensity, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'emc_account']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_ltd = pd.merge(em_propensity, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'long_term_deposit']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_dc = pd.merge(em_propensity, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'debit_card']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_propensity_ = full_df_trans_.drop_duplicates()\n",
    "prd_prop_to_merge = cp.drop('pk_partition', axis=1).drop_duplicates().set_index('pk_cid')\n",
    "em_propensity_pp_ = pd.merge(em_propensity_, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'pension_plan']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_emc_ = pd.merge(em_propensity_,prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'emc_account']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_ltd_ = pd.merge(em_propensity_, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'long_term_deposit']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()\n",
    "em_propensity_dc_ = pd.merge(em_propensity_, prd_prop_to_merge[['Products_contracted','Products_holding_sum', 'debit_card']], \n",
    "                            how = 'left', left_index = True, right_index = True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(em_propensity_pp,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_pp\")\n",
    "pd.to_pickle(em_propensity_emc,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_emc\")\n",
    "pd.to_pickle(em_propensity_ltd,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_ltd\")\n",
    "pd.to_pickle(em_propensity_dc,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_dc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(em_propensity_pp_,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_pp_\")\n",
    "pd.to_pickle(em_propensity_emc_,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_emc_\")\n",
    "pd.to_pickle(em_propensity_ltd_,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_ltd_\")\n",
    "pd.to_pickle(em_propensity_dc_,\"C:/Users/Usuario/Desktop/Proyects/Easy Money/EasyMoney_/pickles/em_propensity_dc_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
